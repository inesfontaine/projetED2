{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "51ca20ebe4d9f4c9bea280f97ee9cbe972c8b10e983d99e82a066eabf95f65e8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Equations de Lotka-Volterra\n",
    "\n",
    "## Guillaume Rouy & Inès Fontaine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "On introduit les fonctions $x_1 : I \\subset \\mathbb{R} \\longrightarrow \\mathbb{R}^+$ et $x_2 : I \\subset \\mathbb{R} \\longrightarrow \\mathbb{R}^+$ représentant respectivement le nombre de proies et de prédateurs à chaque instant. Le système de Lotka-Volterra, avec quatre réels strictement positifs $\\alpha$, $\\beta$, $\\gamma$, et $\\delta$, est donné par :\n",
    "\n",
    "\n",
    "$$\n",
    "\\left\\{ \\begin{array}{cl}\n",
    "\\overset{.}{x_1} = x_1 (\\alpha - \\beta x_2) \\\\\n",
    "\\overset{.}{x_2} = -x_2 (\\gamma - \\delta x_1)\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "On pose donc le vecteur $x=(x_1,x_2)$ et la fonction $f : (x_1,x_2) \\in \\mathbb{R}^2 \\longrightarrow (x_1 (\\alpha - \\beta x_2),-x_2 (\\gamma - \\delta x_1))\\in \\mathbb{R}^2$ de manière à ce que le système devienne simplement l'équation $\\overset{.}{x} = f(x)$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 1\n",
    "\n",
    "#### Interprétation des coefficients\n",
    "\n",
    "Hypothèses :\n",
    "- Les proies ont une source de nourriture illimitée\n",
    "- Les proies ne peuvent mourir qu'à cause des prédateurs\n",
    "- Les prédateurs ne peuvent se nourrir que des proies\n",
    "- Les prédateurs meurent naturellement\n",
    "\n",
    "Ainsi :\n",
    "- Le nombre de proies augmente naturellement par reproduction : taux de reproduction $\\alpha$ sans couplage ($\\alpha x_1$)\n",
    "- Le nombre de proies diminue car ils sont chassés par les prédateurs : taux de chasse $\\beta$ avec couplage ($-\\beta x_1 x_2$)\n",
    "- Le nombre de prédateurs diminue naturellement : taux de décès $\\gamma$ sans couplage ($-\\gamma x_2$)\n",
    "- Le nombre de prédateurs augmente si leur nourriture est abondante : taux de reproduction $\\delta$ avec couplage ($\\delta x_1 x_2$)\n",
    "\n",
    "### Points d'équilibre\n",
    "\n",
    "Les points d'équlibre sont donnés par la résolution du système $f(x1,x2)=0$. On trouve deux points, $O$ et $\\overline{x}$ :\n",
    "$$\n",
    "\\left\\{ \\begin{array}{cl}\n",
    "O = (0,0) \\\\\n",
    "\\overline{x} = (\\frac{\\delta}{\\gamma},\\frac{\\alpha}{\\beta})\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "#### Stabilité : méthode du linéarisé tangent\n",
    "\n",
    "La jacobienne de la fonction $f$ est donnée par :\n",
    "$$\n",
    "J_f (x_1,x_2) =\\begin{pmatrix}\n",
    "\\alpha -\\beta x_2 & \\beta x_1 \\\\\n",
    "-\\delta x_2 & -\\gamma + \\delta x_1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Ainsi, en l'évaluant aux points d'équilibres :\n",
    "\n",
    "- $\n",
    "J_f (0,0) = \\begin{pmatrix}\n",
    "\\alpha & 0 \\\\\n",
    "0 & -\\gamma \n",
    "\\end{pmatrix}\n",
    "$ possède une valeur propre de partie réelle strictement positive ($\\alpha$), donc le point d'équilibre (0,0) est instable.\n",
    "\n",
    "- $\n",
    "J_f (\\frac{\\delta}{\\gamma},\\frac{\\alpha}{\\beta}) = \\begin{pmatrix}\n",
    "0 & \\beta \\frac{\\delta}{\\gamma} \\\\\n",
    "-\\delta \\frac{\\alpha}{\\beta} & 0\n",
    "\\end{pmatrix}\n",
    "$ admet un polynôme caractéristique $X^2 + \\delta^2 = (X-i\\delta)(X+i\\delta)$. Le cours ne permet pas de conclure sur la stabilité de $\\overline{x}$ par cette méthode."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Coefficients de prédation\n",
    "a = 5\n",
    "b = 1\n",
    "g = 5\n",
    "d = 1\n",
    "\n",
    "# Intervalles\n",
    "x1 = np.linspace(0,10,10)\n",
    "x2 = np.linspace(0,10,10)\n",
    "\n",
    "def f1(x1,x2):\n",
    "    return x1*(a - b*x2)\n",
    "\n",
    "def f2(x1,x2):\n",
    "    return -x2*(g-d*x1)\n",
    "\n",
    "X, Y = np.meshgrid(x1, x2)\n",
    "U = f1(X,Y)\n",
    "V = f2(X,Y)\n",
    "\n",
    "# quiver\n",
    "plt.quiver(X,Y,U,V)\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.title('Champs de vecteurs')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# streamplot\n",
    "plt.streamplot(X,Y,U,V)\n",
    "plt.ylabel('$\\dot{x}$')\n",
    "plt.xlabel('$x$')\n",
    "plt.title('Portrait de phase')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "source": [
    "On observe que le portrait de phase semble consister en des courbes fermées concentriques autour du point $\\overline{x}$. Ce point semble donc stable mais pas attractif."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 3\n",
    "\n",
    "Soit $x_0 = (x_{10},x_{20})$ la condition initiale du système en $t=t_0$. Comme $f$ est de classe $\\mathcal{C}^1$, le théorème de Cauchy-Lipschitz assure l'existence d'une unique solution maximale $x=(x_1,x_2)$ sur $I$ ouvert contenant un voisinage de $t_0$.\n",
    "\n",
    "Montrons que pour tout si, $x_0 = (x_{10},x_{20}) \\in {{\\mathbb{R}^{*}_+}}^2 $, alors $t \\ge t_0$, $x(t) \\in {{\\mathbb{R}^{*}_+}}^2$.\n",
    "\n",
    "Supposons que $x_0 = (x_{10},x_{20}) \\in {{\\mathbb{R}^{*}_+}}^2 $ et qu'il existe $T$ tel que $x(T)=(0,x_2(T))$. Alors $\\forall t \\gt T, x(t)=(0,x_{2}(T) e^{-\\gamma (t-T)})$ est une solution. Par unicité, c'est l'unique solution.\n",
    "\n",
    "Considérons maintenant le problème de Cauchy de condition initiale $x^{*} = x(T) = (0, x_2^{*})$, il admet donc une solution qui vaut $x_0$ au temps $t_0$ et $\\forall t \\gt T, x(t)=(0,x_{2}(T) e^{-\\gamma (t-T)})$. \n",
    "\n",
    "Mais il existe une autre solution, $x(t) = (0, x_{2}^{*} e^{-\\gamma (t-T)} ),  \\forall t \\in I$, ce qui est impossible par unicité. \n",
    "\n",
    "En raisonnant de manière analogue pour $x_{2}$, on obtient donc que si $x_0 = (x_{10},x_{20}) \\in {{\\mathbb{R}^{*}_+}}^2 $, alors $t \\ge t_0$, $x(t) \\in {{\\mathbb{R}^{*}_+}}^2$.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 4\n",
    "\n",
    "#### Conservation de $H$\n",
    "\n",
    "On pose, sur ${{\\mathbb{R}^{*}_+}}^2$, la quantité :\n",
    "$$\n",
    "H(x_1,x_2) = \\delta x_1 - \\gamma \\ln{x_1} + \\beta x_2 - \\alpha \\ln{x_2}\n",
    "$$\n",
    "La règle de la chaine donne :\n",
    "$$\n",
    "\\overset{.}{H}(x_1,x_2) = \\delta \\overset{.}{x_1} - \\gamma \\frac{\\overset{.}{x_1}}{x_1} + \\beta \\overset{.}{x_2} - \\alpha \\frac{\\overset{.}{x_2}}{x_2}\n",
    "$$\n",
    "Et en simplifiant à l'aide des équations différentielles :\n",
    "$$\n",
    "\\overset{.}{H}(x_1,x_2) = 0\n",
    "$$\n",
    "Ainsi, la quantité $H(x_1,x_2)$ est conservée, elle reste égale à $H(x_{10},x_{20})$, où le point initial est $x_0=(x_{10},x_{20})$. C'est, en quelque sorte, l'énergie du système proie/prédateur.\n",
    "$$ \n",
    "$$\n",
    "\n",
    "#### Définition temporelle sur l'axe réel\n",
    "\n",
    "On travaille sur l'intégrale première du mouvement :\n",
    "$$\n",
    "H(x_1,x_2) = \\delta x_1 - \\gamma \\ln{x_1} + \\beta x_2 - \\alpha \\ln{x_2}\n",
    "$$\n",
    "On peut montrer que la fonction $x \\in \\mathbb{R_+^*} \\longrightarrow \\delta x- \\gamma \\ln{x}$ admet un minimum global en $\\gamma / \\delta $, qui vaut alors $m = \\gamma (1-\\ln{\\gamma / \\delta})$. On a alors, pour tout $x_1 \\in \\mathbb{R_+^*}$:\n",
    "$$\n",
    "\\delta x_1 - \\gamma \\ln{x_1} \\ge  m\n",
    "$$\n",
    "Et ainsi, pour tout $(x_1,x_2) \\in {\\mathbb{R_+^*}}^2$ : \n",
    "$$\n",
    "H(x_1,x_2) \\ge  m + \\beta x_2 - \\alpha \\ln{x_2}\n",
    "$$\n",
    "Par ailleurs, il existe $C_2>0$ tel que $\\forall x_2 \\ge C_2$, $\\alpha \\ln{x_2} \\le  \\frac{\\beta x_2}{2}$. Ainsi, pour $x_2 \\ge C_2$ :\n",
    "$$\n",
    "H(x_1,x_2) \\ge  m + \\beta x_2 - \\alpha \\ln{x_2} \\ge m + \\beta x_2 - \\frac{\\beta x_2}{2} = m + \\frac{\\beta}{2} x_2\n",
    "$$\n",
    "C'est à dire :\n",
    "$$\n",
    "x_2 \\le \\frac{2}{\\beta}(H(x_{1},x_{2}) - m)\n",
    "$$\n",
    "Or, $H(x_1,x_2)=H(x_{10},x_{20})$ est une quantité constante. Ainsi, pour tout $x_2 \\in \\mathbb{R_+^*}$:\n",
    "$$\n",
    "0 \\lt x_2 \\le \\text{max}(C_2,\\frac{2}{\\beta}(H(x_{10},x_{20}) - \\gamma (1-\\ln{\\gamma / \\delta})) )\n",
    "$$\n",
    "\n",
    "Ce raisonnement peut être appliqué de la même manière pour tout $x_1\\in \\mathbb{R_+^*}$, pour lequel il existe $C_1>0$ tel que :\n",
    "$$\n",
    "0 \\lt x_1 \\le \\text{max}(C_1,\\frac{2}{\\delta}(H(x_{10},x_{20}) - \\alpha (1-\\ln{\\alpha / \\beta})) )\n",
    "$$\n",
    "\n",
    "Ainsi, $\\left\\| f(x) \\right\\|$ est bornée, ce qui permet d'appliquer le critère d'existence globale, et on conclut que toute solution maximale initialisée dans ${\\mathbb{R_+^*}}^2$ est définie sur $\\mathbb{R}$ en entier.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 5\n",
    "\n",
    "#### Courbes de niveau de $H$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5\n",
    "b = 1\n",
    "g = 5\n",
    "d = 1\n",
    "\n",
    "x1 = np.linspace(0,10,100)\n",
    "x2 = np.linspace(0,10,100)\n",
    "\n",
    "def H(x1,x2):\n",
    "    return d*x1 - g*np.log(x1) + b*x2 - a*np.log(x2)\n",
    "\n",
    "X, Y = np.meshgrid(x1, x2)\n",
    "Z = H(X, Y)\n",
    "fig, ax = plt.subplots()\n",
    "contour_set = plt.contourf(X, Y, Z, levels=100)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$x_1$\") \n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.gca().set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "fig=plt.figure()\n",
    "ax=fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(X,Y,Z)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "#### Stabilité du point d'équilibre $\\overline{x}$ : méthode graphique\n",
    "\n",
    "On sait que les trajectoires $t \\longrightarrow (x_1(t),x_2(t))$ se font à $H(x_1,x_2)$ constant. Ainsi, les trajectoires suivent les cercles concentriques que constituent les iso-H autour du point d'équilibre $\\overline{x}$. Or, on remarque que le minimum de $H$ est atteint au point d'équilibre $\\overline{x}$. Ce point représente donc, à lui seul, une trajectoire du système proie/prédateur, qui est fixe. On en déduit que $\\overline{x}$ est stable.\n",
    "\n",
    "$$ \n",
    "$$\n",
    "\n",
    "#### Stabilité du point d'équilibre $\\overline{x}$ : méthode analytique\n",
    "\n",
    "Le linéarisé tangent n'a pas permis de conclure au début. Or, pour montrer analytiquement qu'un point d'équilibre est stable, on peut aussi utiliser la caractérisation par Lyapunov. On sait que la fonction de Lyapunov est souvent représentatrice de l'énergie du système. On pose donc, pour tout $x=(x_1,x_2)\\in {\\mathbb{R_+^*}}^2$, $V(x)= H(x) - H(\\overline{x})$. On vérifie que $V$ est une fonction de Lyapunov pour la fonction $f$ :\n",
    "\n",
    "- $V$ est de classe $\\mathcal{C}^1$ de ${\\mathbb{R_+^*}}^2$ dans $\\mathbb{R_+}$ (car $H$ est de classe $\\mathcal{C}^1$)\n",
    "- $\\forall x \\in {\\mathbb{R_+^*}}^2, x \\neq \\overline{x} \\Rightarrow  V(x)>0$ (car $H(\\overline{x})$ est le minimum global de $H$ )\n",
    "- $V(\\overline{x})=0$\n",
    "\n",
    "Soit $x \\in {\\mathbb{R_+^*}}^2$. Calculons le gradient de $V$ :\n",
    "$$\n",
    "\\nabla V(x) = (\\delta - \\gamma / x_1 , \\beta - \\alpha / x_2)\n",
    "$$\n",
    "Et le produit scalaire avec $f(x)$ donne :\n",
    "$$\n",
    "\\left\\langle \\nabla V(x)|f(x) \\right\\rangle= x_1 (\\delta - \\gamma / x_1) (\\alpha - \\beta x_2) - x_2 (\\beta - \\alpha / x_2)( \\delta x_1 - \\gamma))\n",
    "$$\n",
    "Soit :\n",
    "$$\n",
    "\\left\\langle \\nabla V(x)|f(x) \\right\\rangle=(\\delta x_1 - \\gamma)(\\alpha - \\beta x_2) + (\\beta x_2 - \\alpha)( \\delta x_1 - \\gamma)) = 0\n",
    "$$\n",
    "Ainsi, la caractérisation par Lyapunov assure que le point d'équilibre $\\overline{x}$ est stable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 6"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "\n",
    "def solve_euler_explicit(f, x0, dt, t0, tf):\n",
    "    x =[x0]\n",
    "    imax = int((tf-t0)/dt)\n",
    "    i = 0\n",
    "    t = [t0 + i*dt for i in range (imax+1)]\n",
    "    while i < imax:\n",
    "        x.append(x[i] + f(t[i], *x[i]) * dt)\n",
    "        i += 1\n",
    "    return (t,x)\n",
    "\n",
    "\n",
    "## Test sur une fonction connue\n",
    "def f1(t, x, y):\n",
    "    return np.array([x, t*t*y])\n",
    "\n",
    "time,sol = solve_euler_explicit(f1, [1,1], 0.01, 0, 10)\n",
    "x1 = []\n",
    "x2 = []\n",
    "for x in sol:\n",
    "    x1.append(x[0])\n",
    "    x2.append(x[1])\n",
    "\n",
    "x1true = [exp(t) for t in time]\n",
    "x2true = [exp(t*t*t/3) for t in time]\n",
    "\n",
    "plt.plot(time, x1, label ='Solution approchée par solve_euler_explicit')\n",
    "plt.plot(time, x1true, label = 'Solution exacte')\n",
    "plt.xlabel('Temps')\n",
    "plt.ylabel('$x_1(t)$')\n",
    "plt.title('Représentation des solutions approchée et exacte de l\\'équation $\\dot{x}(t) = tx$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## Graphe de l'erreur \n",
    "erreur = []\n",
    "delta = [10**(-i) for i in range (1,6)]\n",
    "for dt in delta:\n",
    "    time, sol = solve_euler_explicit(f1, [1,1], dt, 0, 10)\n",
    "    x1true = [exp(t) for t in time]\n",
    "    x1true = np.asarray(x1true)\n",
    "    sol = np.asarray(sol)\n",
    "    solu = sol[:,0]\n",
    "    erreur.append(max(list(abs(solu - x1true))))\n",
    "\n",
    "plt.plot(delta, erreur)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title('Evolution de l\\'erreur commise par solve_euler_explicit en fonction du pas de temps choisi')\n",
    "plt.xlabel('Pas de temps')\n",
    "plt.ylabel('Erreur')\n",
    "\n"
   ]
  },
  {
   "source": [
    "On vérifie que l'erreur décroit lorsque le pas de temps tend vers 0.\n",
    "Pour connaitre l'odre de convergence, on trace $\\max_{1<\\text{j}<\\text{J}} \\parallel x^{j} - x(t_j)\\parallel $ où $x^{j}$ est la solution approchée par l'algorithme au temps $t_0 + j*\\Delta t$ et $x(t_j)$ est la solution exacte au même temps, en fonction de $\\Delta t$. On remarque que le graphique de l'erreur est une droite de pente -1 ce qui montre bien que l'erreur est d'ordre 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 7"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Equation de Lotka-Volterra \n",
    "\n",
    "# Coefficients de prédation\n",
    "a = 5\n",
    "b = 1\n",
    "g = 5\n",
    "d = 1\n",
    "\n",
    "#Résolution \n",
    "def f(t, x1, x2):\n",
    "    return np.array([x1*(a-b*x2), -x2*(g-d*x1)])\n",
    "\n",
    "time, sol = solve_euler_explicit(f, [1, 1], 0.001, 0, 15)\n",
    "x1 = []\n",
    "x2 = []\n",
    "for x in sol:\n",
    "    x1.append(x[0])\n",
    "    x2.append(x[1])\n",
    "\n",
    "plt.plot(time, x1, label ='Nombre de proies')\n",
    "plt.plot(time, x2, label='Nombre de prédateurs')\n",
    "plt.xlabel('Temps')\n",
    "plt.title('Représentation des solutions par solve_euler_explicit du problème de Lotka-Volterra')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Fonction H\n",
    "def H(x1,x2):\n",
    "    return d*x1 - g*np.log(x1) + b*x2 - a*np.log(x2)"
   ]
  },
  {
   "source": [
    "On remarque que le maximum local a tendance à augmenter au cours du temps. Cela semble peu fidèle à la réalité car la population devrait avoir un maximum local constant, étant donné que la quantité H est conservée."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 8"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "def solve_euler_implicit(f, x0, dt, t0, tf, itermax = 100):\n",
    "    x =[x0]\n",
    "    imax = int((tf-t0)/dt)\n",
    "    i = 0\n",
    "    t = [t0 + i*dt for i in range (imax+1)]\n",
    "    while i < imax:\n",
    "        xnew = fsolve(lambda y:y-x[i] - f(t[i+1], *y) * dt, x[i] + f(t[i], *x[i]) * dt)\n",
    "        x.append(xnew)\n",
    "        i += 1\n",
    "    return t, x\n",
    "\n",
    "## Test sur une fonction connue\n",
    "def f1(t, x, y):\n",
    "    return np.array([t*x, t*t*y])\n",
    "\n",
    "time,sol = solve_euler_implicit(f1, [1,1], 0.001, 0, 10)\n",
    "x1 = []\n",
    "x2 = []\n",
    "for x in sol:\n",
    "    x1.append(x[0])\n",
    "    x2.append(x[1])\n",
    "\n",
    "x1true = [exp(t*t/2) for t in time]\n",
    "x2true = [exp(t*t*t/3) for t in time]\n",
    "\n",
    "plt.plot(time, x1, label ='Solution approchée par solve_euler_implicit')\n",
    "plt.plot(time, x1true, label = 'Solution exacte')\n",
    "plt.xlabel('Temps')\n",
    "plt.ylabel('$x_1(t)$')\n",
    "plt.title('Représentation des solutions approchée et exacte de l\\'équation $\\dot{x}(t) = tx$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## Application à l'équation de Lotka-Volterra \n",
    "\n",
    "# Coefficients de prédation\n",
    "a = 5\n",
    "b = 1\n",
    "g = 5\n",
    "d = 1\n",
    "\n",
    "#Résolution \n",
    "def f(t, x1, x2):\n",
    "    return np.array([x1*(a-b*x2), -x2*(g-d*x1)])\n",
    "\n",
    "time, sol = solve_euler_implicit(f, [1, 1], 0.001, 0, 15)\n",
    "x1 = []\n",
    "x2 = []\n",
    "for x in sol:\n",
    "    x1.append(x[0])\n",
    "    x2.append(x[1])\n",
    "\n",
    "plt.plot(time, x1, label ='Nombre de proies')\n",
    "plt.plot(time, x2, label='Nombre de prédateurs')\n",
    "plt.xlabel('Temps')\n",
    "plt.title('Représentation des solutions par solve_euler_implicit du problème de Lotka-Volterra')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Ici encore, en testant sur une fonction connue $\\dot{x}(t) = tx $, on s'apreçoit que solve_euler_implicit semble fonctionner.\n",
    "\n",
    "Lorsqu'on utilise ce nouvel algorithme pour résoudre l'équation de Lotka-Volterra, on a l'inverse de solve_euler_explicit: le maximum local semble diminuer. Cela nous semble encore peu fidèle à la réalité car ce maximum devrait être constant. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 9\n",
    "\n",
    "Le nouveau système est :\n",
    "\n",
    "$$\n",
    "\\left\\{ \\begin{array}{cl}\n",
    "\\overset{.}{x_1} = x_1 (\\alpha - \\beta x_2) -u_1(x_1,x_2)(H(x_1,x_2)-H_0) \\\\\n",
    "\\overset{.}{x_2} = -x_2 (\\gamma - \\delta x_1)-u_2(x_1,x_2)(H(x_1,x_2)-H_0)\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "\n",
    "$H$ est constante : $\\forall (x_1, x_2) \\in \\mathbb{R}_+^{2}, H(x_1, x_2) = H_0$. Le nouveau système est identique au système de Lotka-Volterra, quelle que soit la fonction $u=(u_1,u_2)$.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 10\n",
    "\n",
    "$$\n",
    "H(x_1,x_2) = \\delta x_1 - \\gamma \\ln{x_1} + \\beta x_2 - \\alpha \\ln{x_2}\n",
    "$$\n",
    "La règle de la chaine donne :\n",
    "$$\n",
    "\\frac{d (H(x_1,x_2)-H_0)}{dt}= \\delta \\overset{.}{x_1} - \\gamma \\frac{\\overset{.}{x_1}}{x_1} + \\beta \\overset{.}{x_2} - \\alpha \\frac{\\overset{.}{x_2}}{x_2}\n",
    "$$\n",
    "\n",
    "Soit en remplaçant à l'aide du nouveau système:\n",
    "$$\n",
    "\\frac{d (H(x_1,x_2)-H_0)}{dt}= \\delta (x_1 (\\alpha - \\beta x_2) -u_1(x_1,x_2)(H(x_1,x_2)-H_0)) - \\gamma \\frac{x_1 (\\alpha - \\beta x_2) -u_1(x_1,x_2)(H(x_1,x_2)-H_0)}{x_1} + \\beta (-x_2 (\\gamma - \\delta x_1)-u_2(x_1,x_2)(H(x_1,x_2)-H_0)) - \\alpha \\frac{-x_2 (\\gamma - \\delta x_1)-u_2(x_1,x_2)(H(x_1,x_2)-H_0)}{x_2}\n",
    "$$\n",
    "Soit :\n",
    "$$\n",
    "\\frac{d (H(x_1,x_2)-H_0)}{dt}= \\Big(-\\delta u_1(x_1,x_2) + \\gamma \\frac{u_1(x_1,x_2)}{x_1} - \\beta u_2(x_1,x_2) + \\alpha \\frac{u_2(x_1,x_2)}{x_2} \\Big) (H(x_1,x_2)-H_0)\n",
    "$$\n",
    "$$\n",
    "\\frac{d (H(x_1,x_2)-H_0)}{dt}= \\Big( u_1(x_1,x_2)( \\frac{\\gamma}{x_1} -\\delta) + u_2(x_1,x_2)(\\frac{\\alpha}{x_2} - \\beta) \\Big) (H(x_1,x_2)-H_0)\n",
    "$$\n",
    "Avec un $k$ positif arbitraire, on pose $ u_1(x_1,x_2) = - k( \\frac{\\gamma}{x_1} -\\delta) $ et $u_2(x_1,x_2) = - k (\\frac{\\alpha}{x_2} - \\beta)$.\n",
    "\n",
    "On obtient alors l'expression demandé, vu que $\\nabla H(x) = (\\delta - \\gamma / x_1 , \\beta - \\alpha / x_2)$:\n",
    "$$\n",
    "\\frac{d (H(x_1,x_2)-H_0)}{dt}= -k \\left\\| \\nabla H(x) \\right\\|^{2}(H(x_1,x_2)-H_0)\n",
    "$$\n",
    "\n",
    "On reconnait une équation différentielle homogène du premier ordre, ce qui donne :\n",
    "$$\n",
    "H(x_1,x_2)-H_0 = \\lambda \\exp{( A(t) )}\n",
    "$$\n",
    "Où la primitive $A(t)$ est donnée par :\n",
    "$$\n",
    "A(t)=\\int_{*}^{t} -k \\left\\| \\nabla H(x) \\right\\|^{2} dt =  -k \\int_{*}^{t}  \\left[  ( \\frac{\\gamma}{x_1} -\\delta)^{2} +  (\\frac{\\alpha}{x_2} - \\beta)^{2} \\right] dt\n",
    "$$\n",
    "Or, on peut minorer la quantité $(\\gamma/x_1-\\delta)^2$ à l'aide de l'encadrement réalisé à la question 4 :\n",
    "$$\n",
    "0\\lt x_1 \\lt M \\implies 1/x_1 \\gt  1/M \\implies \\gamma/x_1-\\delta >\\gamma/M-\\delta \\implies (\\gamma/x_1-\\delta)^2 > (\\gamma/M-\\delta)^2 \\ge 0\n",
    "$$\n",
    "Et de cette manière :\n",
    "$$\n",
    "-k\\int_{*}^{t} (\\gamma/x_1-\\delta)^2 dt \\lt -k \\int_{*}^{t}(\\gamma/M-\\delta)^2 dt = -k (\\gamma/M-\\delta)^2 t \\le  0\n",
    "$$\n",
    "En somme :\n",
    "$$\n",
    "A(t)=\\int_{*}^{t} -k \\left\\| \\nabla H(x) \\right\\|^{2} dt \\lt -k \\left[ (\\gamma/M-\\delta)^2 + (\\alpha/M'-\\beta)^2 \\right] t\n",
    "$$\n",
    "Et $A(t)$ tend vers $-\\infty$, ce qui montre que $H(x_1,x_2)$ tend vers $H_0$ de manière exponentielle dans le temps."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 11\n",
    "\n",
    "#### Modification du schéma d'Euler\n",
    "\n",
    "Le calcul précédant assure que si on modifie légèrement le système sans perdre l'équivalence, on peut le contraindre à obéir à une condition de plus : la quantité $H$ converge vers une valeur fixée $H_0$. Il suffit de prendre $H_0=H(x_0)$ pour forcer $H$ à rester égale à la valeur initiale de $H$, ce qui doit empêcher les maxima des solutions de varier comme on l'a vu précédemment.\n",
    "\n",
    "#### Rôle et valeur de $k$\n",
    "\n",
    "La valeur de $k$ est un paramètre de vitesse de convergence : plus il est élevé, plus $H$ converge rapidement vers la valeur $H_0$. On a fait l'expérience pour Euler implicite. Malgré tout, il n'est pas sage de choisir un $k$ trop élevé par rapport à ce dont on a besoin, car cela augmente le temps de calcul et la mémoire utilisée les calculs. On prendra donc, pour $t\\in \\left[0;15\\right]$ :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1"
   ]
  },
  {
   "source": [
    "#### Euler explicite\n",
    "\n",
    "$k=1$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Equation de Lotka-Volterra \n",
    "\n",
    "# Coefficients de prédation\n",
    "a = 5\n",
    "b = 1\n",
    "g = 5\n",
    "d = 1\n",
    "\n",
    "# Initialisation :\n",
    "x0 = [1, 1]\n",
    "H0 = H(x0[0],x0[1])\n",
    "\n",
    "# Fonctions ajoutées\n",
    "\n",
    "def u1(x1,x2):\n",
    "    return - k*(g/x1 - d)\n",
    "\n",
    "def u2(x1,x2):\n",
    "    return - k*(a/x2 - b)\n",
    "\n",
    "#Résolution \n",
    "def f(t, x1, x2):\n",
    "    return np.array([x1*(a-b*x2) - u1(x1,x2)*(H(x1,x2)-H0), -x2*(g-d*x1) - u2(x1,x2)*(H(x1,x2)-H0)])\n",
    "\n",
    "time, sol = solve_euler_explicit(f, x0, 0.001, 0, 15)\n",
    "x1 = []\n",
    "x2 = []\n",
    "for x in sol:\n",
    "    x1.append(x[0])\n",
    "    x2.append(x[1])\n",
    "\n",
    "plt.plot(time, x1, label ='Nombre de proies')\n",
    "plt.plot(time, x2, label='Nombre de prédateurs')\n",
    "plt.xlabel('Temps')\n",
    "plt.title('Représentation des solutions par solve_euler_explicit du problème de Lotka-Volterra modifié')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "#### Euler implicite\n",
    "\n",
    "On voit ici l'influence du paramètre $k$ (premier graphe : $k=1$, deuxième graphe : $k=0,0001$) : plus $k$ est grand, plus on peut élargir l'intervalle de temps sans que la décroissance progressive des maxima soit visible. D'ailleurs, si on prend $k=0$, on retrouve bien le cas précédant. On peut aussi voir que pour $k$ bien trop élevé, les calculs sont plus longs et la mémoire prise est tellement grande que les calculs s'arrêtent plus tôt que prévu."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Application à l'équation de Lotka-Volterra \n",
    "\n",
    "# Coefficients de prédation\n",
    "a = 5\n",
    "b = 1\n",
    "g = 5\n",
    "d = 1\n",
    "\n",
    "# Initialisation :\n",
    "x0 = [1, 1]\n",
    "H0 = H(x0[0],x0[1])\n",
    "\n",
    "#Résolution \n",
    "def f(t, x1, x2):\n",
    "    return np.array([x1*(a-b*x2) - u1(x1,x2)*(H(x1,x2)-H0), -x2*(g-d*x1) - u2(x1,x2)*(H(x1,x2)-H0)])\n",
    "\n",
    "time, sol = solve_euler_implicit(f, x0, 0.001, 0, 15)\n",
    "x1 = []\n",
    "x2 = []\n",
    "for x in sol:\n",
    "    x1.append(x[0])\n",
    "    x2.append(x[1])\n",
    "\n",
    "plt.plot(time, x1, label ='Nombre de proies')\n",
    "plt.plot(time, x2, label='Nombre de prédateurs')\n",
    "plt.xlabel('Temps')\n",
    "plt.title('Représentation des solutions par solve_euler_implicit du problème de Lotka-Volterra modifié')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Maintenant, pour $k=0.001$ : $H$ n'est plus assez constante, on voit la décroissance comme avant."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Application à l'équation de Lotka-Volterra \n",
    "\n",
    "# Coefficients de prédation\n",
    "a = 5\n",
    "b = 1\n",
    "g = 5\n",
    "d = 1\n",
    "\n",
    "k = 0.0001\n",
    "\n",
    "# Initialisation :\n",
    "x0 = [1, 1]\n",
    "H0 = H(x0[0],x0[1])\n",
    "\n",
    "#Résolution \n",
    "def f(t, x1, x2):\n",
    "    return np.array([x1*(a-b*x2) - u1(x1,x2)*(H(x1,x2)-H0), -x2*(g-d*x1) - u2(x1,x2)*(H(x1,x2)-H0)])\n",
    "\n",
    "time, sol = solve_euler_implicit(f, x0, 0.001, 0, 15)\n",
    "x1 = []\n",
    "x2 = []\n",
    "for x in sol:\n",
    "    x1.append(x[0])\n",
    "    x2.append(x[1])\n",
    "\n",
    "plt.plot(time, x1, label ='Nombre de proies')\n",
    "plt.plot(time, x2, label='Nombre de prédateurs')\n",
    "plt.xlabel('Temps')\n",
    "plt.title('Représentation des solutions par solve_euler_implicit du problème de Lotka-Volterra modifié')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Enfin, pour $k=10000000000$, on peut voir que le temps de calcul est très long, et que le graphe ne se finit pas : la mémoire utilisée est trop grande."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Application à l'équation de Lotka-Volterra \n",
    "\n",
    "# Coefficients de prédation\n",
    "a = 5\n",
    "b = 1\n",
    "g = 5\n",
    "d = 1\n",
    "\n",
    "k = 10000000000\n",
    "\n",
    "# Initialisation :\n",
    "x0 = [1, 1]\n",
    "H0 = H(x0[0],x0[1])\n",
    "\n",
    "#Résolution \n",
    "def f(t, x1, x2):\n",
    "    return np.array([x1*(a-b*x2) - u1(x1,x2)*(H(x1,x2)-H0), -x2*(g-d*x1) - u2(x1,x2)*(H(x1,x2)-H0)])\n",
    "\n",
    "time, sol = solve_euler_implicit(f, x0, 0.001, 0, 15)\n",
    "x1 = []\n",
    "x2 = []\n",
    "for x in sol:\n",
    "    x1.append(x[0])\n",
    "    x2.append(x[1])\n",
    "\n",
    "plt.plot(time, x1, label ='Nombre de proies')\n",
    "plt.plot(time, x2, label='Nombre de prédateurs')\n",
    "plt.xlabel('Temps')\n",
    "plt.title('Représentation des solutions par solve_euler_implicit du problème de Lotka-Volterra modifié')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Ainsi, $k$ ne peut pas être choisi aussi grand que l'on veut : il y a des limites numériques.\n",
    "Calculons, au premier ordre :\n",
    "\n",
    "$$\n",
    "H(x^{j+1}) = H(x^{j}) + \\frac{dH}{dt}(x^j) dt = H(x^{j}) -k \\left\\| \\nabla H(x^j) \\right\\|^{2}(H(x^j)-H_0) dt\n",
    "$$\n",
    "\n",
    "Ici, $dt$ représente le pas de temps, et on peut poser la précision voulue $\\varepsilon = \\left|H(x^j)-H_0\\right|$. Pour avoir $H$ constante, c'est à dire $\\left|H(x^{j+1})-H(x^{j})\\right|\\ll 1$, on doit avoir $ k \\left\\| \\nabla H(x^j) \\right\\|^{2} \\varepsilon dt \\ll 1$. Ainsi, on tombe sur une limitation :\n",
    "$$\n",
    "k \\ll \\frac{1}{\\left\\| \\nabla H(x^j) \\right\\|^{2} \\varepsilon dt} \n",
    "$$\n",
    "\n",
    "Et de manière approximative :\n",
    "$$\n",
    "k \\lt \\frac{1}{\\varepsilon dt} \n",
    "$$\n",
    "\n",
    "Où $\\varepsilon$ est uniquement une contrainte graphique déterminée par la longueur de l'intervalle de temps demandé. Ici, on a montré que cette limite était environ à $k_{max}=10000000000$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}